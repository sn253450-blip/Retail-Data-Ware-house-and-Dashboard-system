import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sqlalchemy import create_engine
import urllib
import datetime
import os
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font, Alignment

# ==================================================
# üîπ 1. SQL Server Connection
# ==================================================
params = urllib.parse.quote_plus(
    "DRIVER={SQL Server};"
    "SERVER=DESKTOP-0E781O1\SQLEXPRESS;"
    "DATABASE=DataWarehouse;"
    "Trusted_Connection=yes;"
)
engine = create_engine(f"mssql+pyodbc:///?odbc_connect={params}")
print("\nüîó Connecting to SQL Server...")
print("‚úÖ Connected successfully to DataWarehouse!\n")

# ==================================================
# üîπ 2. Fetch All Tables
# ==================================================
tables_query = """
SELECT TABLE_SCHEMA, TABLE_NAME
FROM INFORMATION_SCHEMA.TABLES
WHERE TABLE_TYPE IN ('BASE TABLE', 'VIEW');
"""
tables_df = pd.read_sql(tables_query, engine)
print("üìã Tables Found in DataWarehouse:")
print(tables_df, "\n")

# ==================================================
# üîπ 3. Initialize Results
# ==================================================
results = []

# ==================================================
# üîπ 4. Table-by-Table Full Data Quality Check
# ==================================================
for _, row in tables_df.iterrows():
    schema = row["TABLE_SCHEMA"]
    table_name = row["TABLE_NAME"]
    full_name = f"[{schema}].[{table_name}]"
    print(f"\nüîç Testing full table: {full_name}")

    try:
        # Load full table
        df = pd.read_sql(f"SELECT * FROM {full_name}", engine)
        total_rows, total_cols = df.shape

        if total_rows == 0:
            results.append({
                "Table": full_name,
                "Rows": 0,
                "Columns": total_cols,
                "Null_Values": 0,
                "Duplicates": 0,
                "Whitespace_Cells": 0,
                "Invalid_Sales": 0,
                "Invalid_Dates": 0,
                "Integrity_Score": 0,
                "Status": "‚ùå Empty Table"
            })
            print(f"‚ö† {full_name} is empty.")
            continue

        # --- Nulls ---
        null_count = df.isnull().sum().sum()
        null_ratio = round((null_count / (total_rows * total_cols)) * 100, 2)

        # --- Duplicates ---
        duplicate_count = df.duplicated().sum()
        dup_ratio = round((duplicate_count / total_rows) * 100, 2)

        # --- Whitespace ---
        whitespace_count = 0
        for col in df.select_dtypes(include=['object']).columns:
            whitespace_count += df[col].apply(lambda x: isinstance(x, str) and x.strip() != x).sum()
        white_ratio = round((whitespace_count / (total_rows * total_cols)) * 100, 2)

        # --- Invalid Sales / Dates ---
        invalid_sales = 0
        invalid_dates = 0
        for col in df.columns:
            col_lower = col.lower()
            if "sales" in col_lower or "amount" in col_lower:
                # Ensure column is numeric before checking for < 0
                if pd.api.types.is_numeric_dtype(df[col]):
                    invalid_sales += (df[col] < 0).sum()
            if "date" in col_lower:
                # Handle non-datetime objects gracefully
                def is_invalid_date(x):
                    if isinstance(x, (datetime.datetime, datetime.date)):
                        return x.year < 2000 or x.year > datetime.datetime.now().year
                    return False # Not a datetime, so not an 'invalid date' by this check
                
                invalid_dates += df[col].apply(is_invalid_date).sum()

        # --- Integrity Score ---
        integrity_score = max(0, 100 - (null_ratio + dup_ratio + white_ratio + invalid_sales + invalid_dates))

        # --- Status ---
        if integrity_score >= 95:
            status = "‚úÖ Excellent"
        elif integrity_score >= 80:
            status = "üü° Moderate"
        else:
            status = "üî¥ Poor"

        # --- Append result ---
        results.append({
            "Table": full_name,
            "Rows": total_rows,
            "Columns": total_cols,
            "Null_Values": null_count,
            "Duplicates": duplicate_count,
            "Whitespace_Cells": whitespace_count,
            "Invalid_Sales": invalid_sales,
            "Invalid_Dates": invalid_dates,
            "Integrity_Score": round(integrity_score, 2),
            "Status": status
        })

        print(f"‚úÖ Tested {full_name} successfully.")
        print(f"Rows: {total_rows}, Columns: {total_cols}")
        print(f"Nulls: {null_count}, Duplicates: {duplicate_count}, Whitespace: {whitespace_count}")
        print(f"Integrity: {round(integrity_score,2)}% ‚Üí {status}")

    except MemoryError:
        print(f"‚ö† Table {full_name} too large, testing sample instead.")
        sample_df = pd.read_sql(f"SELECT TOP 100000 * FROM {full_name}", engine)
        total_rows, total_cols = sample_df.shape
        null_count = sample_df.isnull().sum().sum()
        duplicate_count = sample_df.duplicated().sum()
        whitespace_count = 0
        for col in sample_df.select_dtypes(include=['object']).columns:
            whitespace_count += sample_df[col].apply(lambda x: isinstance(x, str) and x.strip() != x).sum()

        results.append({
            "Table": full_name,
            "Rows": f"{total_rows} (Sampled)",
            "Columns": total_cols,
            "Null_Values": null_count,
            "Duplicates": duplicate_count,
            "Whitespace_Cells": whitespace_count,
            "Invalid_Sales": 'N/A', # Cannot check invalid sales on sample reliably
            "Invalid_Dates": 'N/A', # Cannot check invalid dates on sample reliably
            "Integrity_Score": "Sample Tested",
            "Status": "‚ö† Large Table - Partial Test"
        })

    except Exception as e:
        results.append({
            "Table": full_name,
            "Rows": 0,
            "Columns": 0,
            "Null_Values": 0,
            "Duplicates": 0,
            "Whitespace_Cells": 0,
            "Invalid_Sales": 0,
            "Invalid_Dates": 0,
            "Integrity_Score": 0,
            "Status": f"‚ùå Error: {e}"
        })
        print(f"‚ùå Error testing {full_name}: {e}")

# ==================================================
# üîπ 5. Save Reports
# ==================================================
result_df = pd.DataFrame(results)
output_dir = os.path.join(os.getcwd(), "Testing_Reports")
os.makedirs(output_dir, exist_ok=True)

excel_path = os.path.join(output_dir, "Retail_Data_Test_Report.xlsx")
csv_path = os.path.join(output_dir, "Retail_Data_Test_Report.csv")

# Save both Excel & CSV (for Power BI)
result_df.to_excel(excel_path, index=False)
result_df.to_csv(csv_path, index=False)

# Format Excel
try:
    wb = load_workbook(excel_path)
    ws = wb.active
    header_fill = PatternFill(start_color="1F4E78", end_color="1F4E78", fill_type="solid")
    header_font = Font(color="FFFFFF", bold=True)
    for cell in ws[1]:
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center")
    
    # Auto-adjust column widths
    for col in ws.columns:
        max_length = 0
        column = col[0].column_letter # Get the column name
        for cell in col:
            try: # Necessary to avoid error on empty cells
                if len(str(cell.value)) > max_length:
                    max_length = len(str(cell.value))
            except:
                pass
        adjusted_width = (max_length + 2)
        ws.column_dimensions[column].width = adjusted_width

    for row in ws.iter_rows(min_row=2, max_col=ws.max_column):
        status_cell = ws.cell(row=row[0].row, column=ws.max_column) # Status is last column
        status = status_cell.value
        
        fill_color = "FFFFFF" # Default white
        if status: # Check if status is not None
            if "Excellent" in str(status):
                fill_color = "C6EFCE" # Green
            elif "Moderate" in str(status):
                fill_color = "FFF2CC" # Yellow
            elif "Poor" in str(status):
                fill_color = "FFC7CE" # Red
            elif "Error" in str(status) or "Empty" in str(status):
                fill_color = "FFC7CE" # Red
            elif "Large" in str(status):
                fill_color = "DDEBF7" # Light Blue
        
        cell_fill = PatternFill(start_color=fill_color, end_color=fill_color, fill_type="solid")
        for cell in row:
            cell.fill = cell_fill

    wb.save(excel_path)
    print(f"\nüìä Excel Report: {excel_path} (Formatted)")
except Exception as e:
    print(f"‚ö† Could not format Excel file: {e}")
    print(f"\nüìä Excel Report (unformatted): {excel_path}")

print(f"üìà Power BI CSV Report: {csv_path}")


# ==================================================
# üîπ 6. Visualization
# ==================================================
print("\nGenerating overview charts...")
# Ensure 'Integrity_Score' is numeric for plotting, handle "Sample Tested"
plot_df = result_df.copy()
plot_df['Integrity_Score'] = pd.to_numeric(plot_df['Integrity_Score'], errors='coerce')
plot_df = plot_df.dropna(subset=['Integrity_Score']) # Drop non-numeric scores for this chart

try:
    sns.set(style="whitegrid")

    # Bar Chart
    if not plot_df.empty:
        plt.figure(figsize=(12, 7))
        sns.barplot(x="Table", y="Integrity_Score", hue="Status", data=plot_df, dodge=False)
        plt.title("üß≠ Data Integrity Score by Table (Full Data)")
        plt.xticks(rotation=45, ha="right")
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, "Integrity_BarChart.png"))
        plt.show()
    else:
        print("‚ö† No numeric integrity scores to plot for Bar Chart.")

    # Pie Chart
    if not result_df.empty:
        plt.figure(figsize=(6, 6))
        status_counts = result_df["Status"].value_counts()
        # Define colors for specific statuses
        status_colors = {
            "‚úÖ Excellent": "#66BB6A",
            "üü° Moderate": "#FFD54F",
            "üî¥ Poor": "#EF5350",
            "‚ùå Empty Table": "#B0BEC5",
            "‚ö† Large Table - Partial Test": "#42A5F5"
        }
        # Get colors in the order of the value_counts index
        colors = [status_colors.get(s, "#BDBDBD") for s in status_counts.index if s in status_colors]

        status_counts.plot.pie(
            autopct="%1.1f%%", startangle=90, colors=colors,
            wedgeprops={'edgecolor': 'white', 'linewidth': 1}
        )
        plt.title("üìä Overall Data Quality Status Distribution")
        plt.ylabel("")
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, "Integrity_PieChart.png"))
        plt.show()
    else:
        print("‚ö† No data to plot for Pie Chart.")

    print("‚úÖ Overview visuals generated successfully!")

except Exception as e:
    print(f"‚ö† Visualization Error: {e}")

# ==================================================
# üîπ 7. Advanced Data Quality Comparison (NEW)
# ==================================================
print("\nGenerating advanced data quality comparison charts...")
try:
    # --- Prepare Data for Layer-by-Layer Comparison ---
    comp_df = result_df.copy()
    
    # Extract schema (bronze, silver, gold) from table name
    comp_df['Schema'] = comp_df['Table'].str.extract(r'\[(.*?)\]')
    
    # Ensure metrics are numeric for aggregation
    metrics_to_check = ['Null_Values', 'Whitespace_Cells'] # Removed 'Duplicates'
    for col in metrics_to_check:
        comp_df[col] = pd.to_numeric(comp_df[col], errors='coerce')
        
    # Drop any rows where extraction or conversion failed
    comp_df = comp_df.dropna(subset=['Schema'] + metrics_to_check)
    
    # Group by schema and sum the metrics
    grouped_metrics = comp_df.groupby('Schema')[metrics_to_check].sum().reset_index()
    
    # Define the correct layer order
    layer_order = ['bronze', 'silver', 'gold']
    
    if not grouped_metrics.empty:
        
        # --- Chart 1: Total Null Values by Layer ---
        plt.figure(figsize=(10, 6))
        ax1 = sns.barplot(data=grouped_metrics, x='Schema', y='Null_Values', palette='Reds_d', order=layer_order)
        plt.title("Advanced Comparison 1: Total Null Values by Layer", fontsize=16)
        plt.ylabel("Total Null Values Count")
        plt.xlabel("Data Warehouse Layer")
        # Add labels on top of bars
        for p in ax1.patches:
            ax1.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),
                         ha='center', va='center', xytext=(0, 9), textcoords='offset points')
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, "Compare_Nulls_by_Layer.png"))
        plt.show()
        print("‚úÖ Generated Null Value comparison chart.")
        
        # --- Chart 2: Total Whitespace Cells by Layer ---
        plt.figure(figsize=(10, 6))
        ax2 = sns.barplot(data=grouped_metrics, x='Schema', y='Whitespace_Cells', palette='Greens_d', order=layer_order)
        plt.title("Advanced Comparison 2: Total Whitespace Cells by Layer", fontsize=16)
        plt.ylabel("Total Cells with Trailing/Leading Whitespace")
        plt.xlabel("Data Warehouse Layer")
        # Add labels on top of bars
        for p in ax2.patches:
            ax2.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),
                         ha='center', va='center', xytext=(0, 9), textcoords='offset points')
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, "Compare_Whitespace_by_Layer.png"))
        plt.show()
        print("‚úÖ Generated Whitespace comparison chart.")
        
    else:
        print("‚ö† Could not generate advanced comparison charts: No metric data found.")

except Exception as e:
    print(f"‚ö† Advanced Comparison Visualization Error: {e}")


print("\n‚úÖ Full-Table Data Testing Completed¬†Successfully!")